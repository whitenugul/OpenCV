1. 적응형 이진화
-> 노이즈를 제거한 뒤에 Otsu 이진화를 적용
-> 영상을 여러 영역으로 나눈 뒤, 그 주변 픽셀 값만 활용하여 임계값을 구함
=> cv2.adaptiveThreshold(영상, 임계값을 만족하는 픽셀에 적용할 값, 임계값 결정 방법, Threshold 적용방법, 블록사이즈, 가감할 상수)
=> 임계값 결정방법
    -> cv2.ADAPTIVE_THRESH_MEAN: 이웃 픽셀의 평균으로 결정
    => 선명하지만 잡티가 많아지는 특징이 있다.
    -> cv2.ADAPTIVE_THRESH_GAUSSIAN_C: 가우시안 분포에 따른 가중치의 합으로 결정
    => 선명도가 조금 떨어지지만 잡티가 적은 특징이 있다.
    -> 블록 사이즈: 3이상의 호출, 블록 사이즈가 클수록 연산 시간이 오래 걸린다.

2. 이미지 유사도
-> 픽셀 값의 분포가 서로 비슷하다면 유사한 이미지일 확률이 높다.
=> cv2.compareHist(히스토그램1, 히스토그램2, 알고리즘)
=> 알고리즘
    -> cv2.HISTCMP_CORREL: 상관관계(1: 완전 일치, -1: 완전 불일치, 0: 무관계)
    -> cv2.HISTCMP_CHISQR: 카이제곱(0: 완전 일치, 무한대: 완전 불일치)
    -> cv2.HISTCMP_INTERSECT: 교차(1: 완전 일치, 0: 완전 불일치)
    -> cv2.HISTCMP_BHATTACHARYYA: 밀도함수(0: 완전 일치, 1: 완전 불일치)

3. 영상의 변환
-> 영상을 구성하는 픽셀의 배치 구조를 변경함으로 전체 영상의 모양을 바꾸는 작업

3-1. 이미지 이동
-> 원래 있던 좌표에 이동할 거리만큼 더해서 보내주면 된다.
=> x_new = x_old + d1
=> y_new = y_old + d2
=> 변환행렬
[ 1 0 d1 ] => cv2.warpaffine(영상, 2*3 구조의 변환행렬, 결과(굳이 넣을 필요는 없음), 보간법 알고리즘)
[ 0 1 d2 ]

=> 보간법 알고리즘
    -> cv2.INTER_LINEAR: 기본값, 인접한 4개 픽셀 값이 거리 가중치를 사용한다.
        => 속도가 빠르지만 퀄리티가 떨어진다.
    -> cv2.INTER_NEAREST: 가장 가까운 픽셀 값을 사용한다.
        => 계산이 빠른편이지만 가까운 픽셀을 사용하기 때문에 퀄리티가 좋을 수 있다.
        => 속도가 가장 빠르다.
        => INTER_LINEAR와 속도가 차이가 많이 나지는 않는다.
    -> cv2.INTER_AREA: 픽셀 영역 관계를 이용한채 샘플링
        => 영역적인 정보를 추출해서 결과 영상을 세팅하는 방법이며 다운 샘플링시 효과적이다.
    -> cv2.INTER_CUBIC: 인접한 16개 픽셀 값에 거리 가중치를 사용한다.
        => 퀄리티는 가장 좋지만 속도가 느린 단점이 있다.
    -> 결과가 (0, 0)이면 입력 영상과 같은 크기의 행렬을 반환한다.

3-2. 크기 변환(resize)
-> 영상의 크기를 원본 영상보다 크게 또는 작게 만드는 변환을 말한다.
=> cv2.resize(영상, 결과, x와 y 방향 스케일 비율, 보간법)

3-3. 회전(rotation)
-> 영상을 특정 각도만큼 회전을 시키는 방법(반시계 방향)
=> cv2.getRotationMatrix2D(중심좌표, 회전각도, 확대비율) -> affine 행렬에 적용을 시킨다.
=> 회전각도는 기본값이 반시계 방향인데 시계방향으로 돌리고 싶다면 음수를 넣으면 된다.

3-4. 투시 변환
-> 직사각형 형태의 영상을 임의의 입체감 있는 사각형 형태로 변경할 수 있는 변환
=> 입체감 있는 사각형은 직사각형의 정사형 같은 모양이라고 생각하면 된다.
-> 원본 영상에 있는 직선은 결과 영상에서 그대로 유지 되지 않고 평행 관계가 깨질 수 있다.
-> 투시 변환은 보통 3 X 3 크기의 실수 행렬로 표현
(8개의 parameter로 표현할 수 있지만, 좌표 계산 편의상 9개의 원소를 갖는 행렬로 사용)
=> cv2.getPerspectiveTransform(영상, 4개의 결과 좌표점)
    -> 결과로 투시 변환 행렬이 나온다.
=> cv2.warpPerspective(영상, 투시 변환 행렬(getPerspectiveTransform의 결과로 나온 투시 변환 행렬), 결과 영상의 크기)
